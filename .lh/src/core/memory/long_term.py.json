{
    "sourceFile": "src/core/memory/long_term.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1731088546647,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1731088546647,
            "name": "Commit-0",
            "content": "# src/core/memory/long_term.py\r\nfrom typing import Dict, Any, List, Optional\r\nfrom datetime import datetime\r\nfrom sqlalchemy import create_engine, Column, String, JSON, DateTime, Text\r\nfrom sqlalchemy.ext.declarative import declarative_base\r\nfrom sqlalchemy.orm import sessionmaker\r\nfrom .base import BaseMemory, MemoryEntry\r\n\r\nBase = declarative_base()\r\n\r\nclass MemoryRecord(Base):\r\n    \"\"\"SQLAlchemy model for long-term memory storage\"\"\"\r\n    __tablename__ = 'long_term_memories'\r\n\r\n    id = Column(String, primary_key=True)\r\n    timestamp = Column(DateTime, nullable=False)\r\n    content = Column(JSON, nullable=False)\r\n    metadata = Column(JSON, nullable=False)\r\n    source = Column(String, nullable=False)\r\n    tags = Column(JSON, nullable=False)\r\n    summary = Column(Text, nullable=True)\r\n    importance_score = Column(Float, nullable=False, default=0.0)\r\n\r\nclass LongTermMemory(BaseMemory):\r\n    \"\"\"Implementation of long-term memory using SQLAlchemy\"\"\"\r\n\r\n    def __init__(self, config: Dict[str, Any]):\r\n        super().__init__(config)\r\n        self.engine = create_engine(config['long_term_db'])\r\n        Base.metadata.create_all(self.engine)\r\n        self.Session = sessionmaker(bind=self.engine)\r\n\r\n    def _initialize_embedder(self):\r\n        \"\"\"Initialize the Groq embedder\"\"\"\r\n        from langchain_community.embeddings import GroqEmbeddings\r\n\r\n        return GroqEmbeddings(\r\n            model=self.config['embedder']['model'],\r\n            groq_api_key=self.config['groq_api_key']\r\n        )\r\n\r\n    async def store(self, entry: MemoryEntry) -> bool:\r\n        \"\"\"Store a memory entry in SQLite database\"\"\"\r\n        try:\r\n            session = self.Session()\r\n\r\n            # Generate summary and importance score\r\n            summary = await self._generate_summary(entry.content)\r\n            importance_score = await self._calculate_importance(entry.content)\r\n\r\n            # Create record\r\n            record = MemoryRecord(\r\n                id=str(entry.timestamp.timestamp()),\r\n                timestamp=entry.timestamp,\r\n                content=entry.content,\r\n                metadata=entry.metadata,\r\n                source=entry.source,\r\n                tags=entry.tags,\r\n                summary=summary,\r\n                importance_score=importance_score\r\n            )\r\n\r\n            session.add(record)\r\n            session.commit()\r\n            session.close()\r\n\r\n            return True\r\n        except Exception as e:\r\n            print(f\"Error storing long-term memory: {str(e)}\")\r\n            session.rollback()\r\n            session.close()\r\n            return False\r\n\r\n    async def retrieve(self, query: str, limit: int = 5) -> List[MemoryEntry]:\r\n        \"\"\"Retrieve memories based on semantic search\"\"\"\r\n        try:\r\n            session = self.Session()\r\n\r\n            # Generate query embedding\r\n            query_embedding = await self._generate_embedding({\"query\": query})\r\n\r\n            # Get all records and calculate similarity\r\n            records = session.query(MemoryRecord).all()\r\n            similarities = []\r\n\r\n            for record in records:\r\n                content_embedding = await self._generate_embedding(record.content)\r\n                similarity = self._calculate_similarity(query_embedding, content_embedding)\r\n                similarities.append((record, similarity))\r\n\r\n            # Sort by similarity and get top results\r\n            similarities.sort(key=lambda x: x[1], reverse=True)\r\n            top_records = similarities[:limit]\r\n\r\n            # Convert to MemoryEntry objects\r\n            entries = []\r\n            for record, _ in top_records:\r\n                entries.append(MemoryEntry(\r\n                    timestamp=record.timestamp,\r\n                    content=record.content,\r\n                    metadata=record.metadata,\r\n                    source=record.source,\r\n                    tags=record.tags\r\n                ))\r\n\r\n            session.close()\r\n            return entries\r\n        except Exception as e:\r\n            print(f\"Error retrieving long-term memories: {str(e)}\")\r\n            session.close()\r\n            return []\r\n\r\n    async def _generate_summary(self, content: Dict[str, Any]) -> str:\r\n        \"\"\"Generate a summary of the memory content\"\"\"\r\n        try:\r\n            content_str = str(content)\r\n            # Use Groq for summarization\r\n            response = await self.llm.agenerate(\r\n                prompts=[f\"Summarize this concisely: {content_str}\"]\r\n            )\r\n            return response.generations[0][0].text\r\n        except Exception as e:\r\n            print(f\"Error generating summary: {str(e)}\")\r\n            return \"\"\r\n\r\n    async def _calculate_importance(self, content: Dict[str, Any]) -> float:\r\n        \"\"\"Calculate importance score for memory\"\"\"\r\n        try:\r\n            content_str = str(content)\r\n            # Use Groq to assess importance\r\n            response = await self.llm.agenerate(\r\n                prompts=[\r\n                    f\"Rate the importance of this information from 0 to 1: {content_str}\"\r\n                ]\r\n            )\r\n            score_str = response.generations[0][0].text\r\n            return float(score_str)\r\n        except Exception as e:\r\n            print(f\"Error calculating importance: {str(e)}\")\r\n            return 0.0"
        }
    ]
}